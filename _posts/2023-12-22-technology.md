---
title: Sufficiently Advanced Technology
author: the-wandmaker
date: 2023-12-21 12:21:00 +0100
categories: [Articles, Technology]
tags: [magic, art, science, philosophy]
pin: false
math: false
mermaid: false
image:
  path: /commons/2023-12-technology.png
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: An AI generated image of an alchemist interacting with advanced technology
---

There is a line plotted, at one point we have a simple mineral, and at another we have a human brain. Somewhere just past minerals lies modern computers, and somewhere between computers and the brain is a form of non-biological mind that we haven't yet created. Many iterations of this brain will exist, the first valid prototypes don't even have to be very complex, perhaps only as sophisticated as a worm. But they will progress, and we will find it very unlikely that the human brain represents the upper limit of intellectual capacity.

In a recent interview, [Elon Musk commented](https://www.cnbc.com/video/2023/11/29/elon-musk-openai-is-lying-when-it-says-it-is-not-using-copyrighted-data.html) on the state of copyrighted materials, such as writing and digital artwork, being used to train commercial AI models. The issue of debate is that artists, writers, etc. are not having their rights observed as designated by copyright law. The opposing argument is that these resources, being publicly accessible, are fair use for companies to train AI models with. Musk's comment was that:

> "by the time these lawsuits are decided we'll have digital god, so you'll have to ask digital god at that point"

Although Musk seems to have become purely a progenitor of meme-worthy statements, the notion of an "AI god" is still intriguing enough to warrant further consideration. We can surmise that his statement is a reference to the concept of artificial super intelligence, or ASI. The concept of ASI represents theoretical future AI technology that has become so advanced that it rivals human intelligence in unparalleled ways. The point at which we reach this level of technological advancement is often referred to as the technological "singularity" ([Ray Kurzweil predicts singularity by 2045](https://futurism.com/kurzweil-claims-that-the-singularity-will-happen-by-2045)). From that point onward, computers could outperform humans in many, if not all tasks. This also tends to imply that ASI would be able to continuously produce improved versions of itself.

It is not unreasonable to imagine that technologies which represent and yield _god-like capabilities_ will eventually (and many already do) exist. A sparse list of examples could possibly include medicinal advancements such as penicillin, the harnessing the power of the atom, or the ability for us to travel faster than the speed of sound, and humans will continue to raise this bar further. But what pushes something over the threshold from being god-like, to full on deification? It is no small feat to create a god, whether this creation be tied into the origins of our collective mythology and ancient ancestors, or possibly... brought about as a product of modern "human ingenuity". A significant challenge resides in trying to identify what a god even is. The fact of the matter is that across the world's vibrant range of cultures, religions, and beliefs, there is no universally agreed upon definition of what constitutes a deity.

The characteristics of various deities vary greatly between many cultures, and broad survey of mythology reveals that there isn't one simple definition for what a god is. They differ in shape (some anthropomorphic, others not), material (physical existence, formlessness, conceptual abstractions, or intangible yet omnipresent), personality and temperance also very. At minimum, a non-exhaustive list of trends may be:

1. They are considered worthy of worship.
2. They exhibit powers or abilities beyond human capacity.
3. They must interact with humans (a god that is perpetually off doing its own thing with no observability or effect on humanity is of little consequence).
4. ** And these interactions with humans should be of a certain nature, they are meaningful or profound in some way.
5. They tend to have a focus or concern over a certain specific interest: crops, war, romance, etc.

In terms of artificial intelligence, there are a few possible avenues through which it could approach reaching these criteria. Consider an artificial super intelligence that is omnipresent (through internet connectivity). It isn't just intelligent, but genuinely wise. Among its abilities is the capability to generate highly accurate predictive models of future events. Further, due to its programming or design, it possesses an innate focus on optimizing a certain problem: eg. food, housing, economics. Although this theoretical entity does not possess a biological brain, let us for the purposes of this discussion at minimum admit that it perhaps possesses intelligence of some kind. As demonstrated with various species of corvids capable of demonstrating incredible feats of complex problem solving, non-human intelligence is intelligence nonetheless.

I'm inclined once again to think of the often over quoted third law by the science fiction author Arthur C. Clarke:

>  _Any sufficiently advanced technology is indistinguishable from magic._

This can be interpreted many ways, but for this discussion I'd like to specifically frame the phrase "indistinguishable from magic" in the same way that we consider lab grown diamonds to be [indistinguishable from natural ones](https://www.grownbrilliance.com/blog/do-lab-created-diamonds-test-as-real/). Whether something emerges from nature, or from a laboratory, it is people who often decide what something is worth.

## Animism

Concepts of [animism](https://en.wikipedia.org/wiki/Animism), the notion that physical objects have a spirit of some kind, reside at the foundation of many spiritual and religious systems. One can only imagine what our ancient ancestors would say if we were able to tell them that we had built upon their ideas to the point where we now have the ability to extract rocks, crystals, and metals from the earth and imbue them with the ability to speak with human voices, move of their own accord, and exceed the strength and speed of most organisms. The constraints imposed upon silicon via the etching process allow this mineral to solve many complex problems, and the fine strands of refined copper ore coiled in different ways can transmit information great distances. It can be somewhat profound to consider that these extraordinary qualities lie latent in the raw materials of the earth around us.

<!--
While discussing this article, my fiancee mentioned her childhood pet rock, and how she had been concerned with taking care of it.
-->

Deus ex machina, a latin phrase, meaning "god is in the machine" originates from ancient Greek theater. It is a plot device in which some unlikely event suddenly occurs, allowing the story to move forward: a god swooping in and carrying a character away to safety for example (the actors sometimes quite literally using a crane that would lower them in on a rope, _hence the machine_).

As unexpected as the _deus ex machina_ of Greek theater, the exact scenario where an "AI god" (or at minimum, a system that is intelligent in relative comparison to humans) emerges into existence may be entirely impossible to predict. Part of the challenge is that highly complex systems often have properties and behaviors at scale that their component parts do not. These are referred to as [emergent properties](https://en.wikipedia.org/wiki/Emergence), and they are not always something that can be anticipated when designing these systems. A few examples include colonies of ants constructing underground tunnel networks, or neurons in the brain (many neurons are needed for thought to be possible). Many scientists have theorized that [consciousness in artificial brains](https://noetic.org/blog/true-artificial-consciousness-is-it-possible/) will likely be the result of emergent properties.

Beyond discussions of somewhat finite systems, we might also be able to take into consideration the properties of intricate world-scale systems; complex networks of social relations, relationships between different species, organic and inorganic parts of our environment, or between AI and humans. After all, greatest impact of technologies always tends to be how we interact with them. At a certain level, all of these systems might be seen to exert influences upon one another.

## Deification

Where do gods come from? Amongst the ancient Greeks, the scholar Euhemerus argued that the gods were originally mortal human rulers who had been venerated and subsequently deified after their lifetimes. Stories of historical events being retold, embellished, and modified eventually gave way to epic myths and legends. Alternatively, the philosopher Democritus hypothesized that various weather, astronomical events, and other natural phenomena were the origin of human conceptions of deities, with stories and personifications being crafted as explanations of these occurrences.

<!--
> Humans have an overactive agency detection system, which has a tendency to conclude that events are caused by intelligent entities, even if they really are not. This is a system which may have evolved to cope with threats to the survival of human ancestors: in the wild, a person who perceived intelligent and potentially dangerous beings everywhere was more likely to survive than a person who failed to perceive actual threats, such as wild animals or human enemies. Humans are also inclined to think teleologically and ascribe meaning and significance to their surroundings, a trait which may lead people to believe in a creator-deity. This may have developed as a side effect of human social intelligence, the ability to discern what other people are thinking.
> ~ https://en.wikipedia.org/wiki/Deity
-->

The theories of these Greek philosophers may at best provide some useful examples of different perspectives, but overall are somewhat lacking the completeness of more nuanced explanations. At minimum we might be able to agree with them that historically there is an inherent relation between humans and the deities of a society, as well as their social and environmental soundings.

In terms of our society today, technology is very much integrated into our environment and our lives, but is this alone enough to allow it to become something more sacred? There is a common tendency to place an excessive amount of praise in the abilities of AI, and other technologies. Typically, this is either done due to a of lack of understanding towards a technology, or intentionally as a marketing tactic. Merely embellishing the significance or abilities of something however, isn't enough to result in some form of deification, and the brand loyalty of multitudes of iPhone users can't quite be considered worship. Comparatively, the sort of "deification" that our society places upon various celebrities also isn't enough to grant these individuals any true from of power beyond human limits.

Overall it simply seems that the stage just isn't set for any sort of ASI to emerge don the title of being an "AI god" anytime soon. A counter argument here might state that ASI would simply just be "that good" and intelligent enough could to convince people to follow its plans (whether they are aware of that, or if those influences would be invisibly distributed through existing infrastructures of social media and advertising networks). Even with access to the best advertising tools and expert marketing teams, it is in no way effortless for a company to simply sell any arbitrary product or service. 100% perfect solutions to problems are not always possible, as explored by the Halting problem (some problems are, by mathematical definition, unsolvable). Even an AI god cannot bypass mathematical constants and constraints. I would wager a guess that at least one aspect of people as individuals, or collectively represents something that is unsolvable per pure mathematical logic.

<!-- Present AI technologies are, at best, just another tool in the toolbox. -->

## Apotheosis

Some problems are unsolvable. In scenarios where a 100% certain solution cannot be achieved, it is often AI that excels at rapidly approaching an optimal outcome. Given this trend it might be pertinent to examine other examples of things that have made headway in advancing how they are perceived towards something that is godlike.

Around this time last year, my internet friend [`@lukefromohio`](https://www.tiktok.com/@lukefromohio) posted an excellent discourse on the subject of Santa Claus. Notably pointing out that the 4th-century bishop of Myra, who progressed into sainthood, is celebrated centuries later as a symbol synonymous with the very "spirit of Christmas". Saint Nicholas has sufficient lore, receives annual veneration, and has countless loyal devotees. Over the passing centuries, Bishop Nicholas of Myra may be one of the closest individuals in history to approach full on [apotheosis](https://en.wikipedia.org/wiki/Apotheosis).

<!-- I couldn't find the original video, but I'm going to hope that my memory is at least 50% accurate and I'll update this later with a link if I can. -->

There is something to be said about the amount of power and influence a person can command, whether they are corporeally real, or something more [egregorical](https://en.wikipedia.org/wiki/Egregore). This is key to the idea that they need to be worthy of whatever form of celebration, veneration, or worship they receive. Worth, again however, is perceived. Specifically in terms of ASI, some semblance of reverence for these technologies could theoretically emerge purely out of their utility. Advancements achieved by AI could improve, if not save lives altogether. These systems could issue advice that could vastly support people's general wellbeing, and possibly be an aspect of modern society that improves life in some way that makes it truly worth exceptional praise. Of course it would have the be the right incarnation of AI, something with personality, or at minimum attributes that the human mind can personify.

<!-- As a society we, rather unfortunately, don't tend to habitually venerate life saving advancements in technology. -->

One of the most important things we can do is probably to discuss these technologies and their implications. If people generally have a good understanding of them, this helps avoid scenarios where false beliefs are unhelpfully applied to them.

## Demonization

Discussions of theoretical technology-based threats against humanity have long been a popular subject of works of fiction. Isaac Asimov's _I, Robot_ is a classic example of a runaway system based in human-imposed rules that advances to a point where its creators are no longer in control of it. Asimov's narrative ends with the robots taking over energy production in order to ensure the survival of humanity. But continuing that progression of advancement, how far could AI go? The theoretical capabilities of computational systems have historically been envisioned to have near immeasurable power. Since the 1800s, mathematicians such as [Pierre-Simon Laplace](https://en.wikipedia.org/wiki/Pierre-Simon_Laplace) have theorized the significant effects of machines capable of vast computational abilities, even going so far to consider what it would mean if those devices were able to model reality with 100% accuracy. With complete knowledge of the state of the universe, and a perfect model of its function, Laplace suggested that no event, past or future, would be unknowable by this intelligence (later this concept would come to be referred to as _Laplace's demon_).

What we see in relation to the possible hazards of AI is vastly a reflection from works of science fiction. Fictional characterizations of future technologies are easily cast onto whatever present object most closely resembles them. Realistically, future perceptions of AI technology will normalize it into something that is as much a part of every day life as the internet or smart phones, rather than portraying an indefinite narrative where it could at any moment randomly become Skynet or The Matrix.

> Lonely and fearful societies tend to invent wrathful, violent, submission-seeking deities, while happier and secure societies tend to invent loving, non-violent, compassionate deities.[^anthropomorphism]

<!-- Follow up question: can we assess the collective views of any post-industrial countries as distinctly "happy" or "fearful" and map this to a general positive or negative view of technology?
-->

As technology advances we are forced to rethink related concepts that previously were more than suitable. The computational power of quantum computers, for example, broadly makes many methods of cryptographic security used to secure passwords obsolete. It cannot be ignored that advanced AI would also pose risks from a security standpoint, and beyond that it may also require us to reconsider many moral and ethical definitions that would cease to be viable in a world where ASI exists.

It seems reasonable to say that at present, artists should have the ability to protect their work and their unique personal styles from other people and companies who would use those designs without permission or attempt to make a profit from them. However, when we consider how humans learn, and then introduce a technology that is also capable of learning, we start to find it necessary to consider if artificial intelligences will require their rights to be creative defended. At the same time, it would be imperative that as we create language to enable AIs to have creative rights, that we don't inadvertently define dehumanizing legislation that breaks down societal definitions of person-hood. Or likewise negatively impact learning and education by creating an information economy with strict regulations on ownership of information. For future generations I leave this message: we used to have libraries, and all of the books were free.

A number of years ago I was able to attended a presentation hosted by Martin Ford, who at the time was promoting his book _Rise of the Robots: Technology and the Threat of a Jobless Future_. He discussed how robots, automation, and AI might effect jobs and pointed out that there had been significant concern amidst the American industrial revolution that automation would take away countless jobs which were previously done by hand, and eliminate people's ability to make any sort of income. Ford concluded that automation has not historically eliminated jobs, new technologies in fact create many more new jobs. The real issue is that automation reduces the value of the work that a person would previously produce. Technological improvements have tended to have direct correlations to individual productivity, which resulted in pay increases due to the subsequent increased success of the company. This was true until 2006, at which point pay increases in proportion to productivity ceased to continue to increase, and at the same time wages have remained relatively unchanged.

To me at least, it seems clear that demonizing technology runs along a similar vein as medieval witch-hunts. We should be focused on the importance of people; supporting and valuing one another, promoting artists, and engaging in thoughtful discourse, rather than pursuing imagined dangers.

A technological entity might not be a suitable replacement for all aspects of divinity, but I won't soon dismiss the possibility that humans might invent something that possesses substantially impressive qualities. Despite the flaws and limitations we all have, it is miraculous that humans have achieved so much, and have so much further yet to go.

***

[^anthropomorphism]: Barrett, Justin L.; Keil, Frank C. (December 1996). "Conceptualizing a Nonnatural Entity: Anthropomorphism in God Concepts" (PDF). Cognitive Psychology. 31 (3): 219–247. https://cogdevlab.yale.edu/sites/default/files/files/barrett%20keil.pdf
